{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9373662-5998-4b60-875a-94c6ca8fe636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gspread\n",
      "  Downloading gspread-6.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-auth\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting google-auth-oauthlib>=0.4.1 (from gspread)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib>=0.4.1->gspread)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.8.30)\n",
      "Downloading gspread-6.2.1-py3-none-any.whl (59 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: rsa, oauthlib, requests-oauthlib, google-auth, google-auth-oauthlib, gspread\n",
      "Successfully installed google-auth-2.41.1 google-auth-oauthlib-1.2.2 gspread-6.2.1 oauthlib-3.3.1 requests-oauthlib-2.0.0 rsa-4.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gspread google-auth pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "403679b5-c174-4209-b600-e0d7d44e0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: gspread in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (6.2.1)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: pyodbc in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from gspread) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from gspread) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pradeep kalluru\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas gspread sqlalchemy pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4d7193-b906-4f77-be2e-0a90eeed31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data automation pipeline...\n",
      "Successfully extracted 250000 rows from Google Sheets.\n",
      "OrderDate successfully standardized to YYYY-MM-DD format.\n",
      "Connected to SQL Server.\n",
      "Cleared existing data from Live_Data_Staging.\n",
      "Loaded 10000 of 250000 rows...\n",
      "Loaded 20000 of 250000 rows...\n",
      "Loaded 30000 of 250000 rows...\n",
      "Loaded 40000 of 250000 rows...\n",
      "Loaded 50000 of 250000 rows...\n",
      "Loaded 60000 of 250000 rows...\n",
      "Loaded 70000 of 250000 rows...\n",
      "Loaded 80000 of 250000 rows...\n",
      "Loaded 90000 of 250000 rows...\n",
      "Loaded 100000 of 250000 rows...\n",
      "Loaded 110000 of 250000 rows...\n",
      "Loaded 120000 of 250000 rows...\n",
      "Loaded 130000 of 250000 rows...\n",
      "Loaded 140000 of 250000 rows...\n",
      "Loaded 150000 of 250000 rows...\n",
      "Loaded 160000 of 250000 rows...\n",
      "Loaded 170000 of 250000 rows...\n",
      "Loaded 180000 of 250000 rows...\n",
      "Loaded 190000 of 250000 rows...\n",
      "Loaded 200000 of 250000 rows...\n",
      "Loaded 210000 of 250000 rows...\n",
      "Loaded 220000 of 250000 rows...\n",
      "Loaded 230000 of 250000 rows...\n",
      "Loaded 240000 of 250000 rows...\n",
      "Loaded 250000 of 250000 rows...\n",
      "Successfully loaded ALL 250000 rows into Live_Data_Staging.\n",
      "SQL Server connection closed.\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from google.oauth2.service_account import Credentials\n",
    "from io import StringIO\n",
    "import urllib.parse\n",
    "\n",
    "# --- 1. GOOGLE SHEETS CONFIGURATION ---\n",
    "GOOGLE_SHEET_NAME = \"Sales_Live_Data\"\n",
    "CREDENTIALS_FILE = \"salesautomation-474410-d0b68cf3a8a2.json\"\n",
    "# Define the scopes for Google Sheets and Drive access\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "    'https://www.googleapis.com/auth/drive.readonly'\n",
    "]\n",
    "\n",
    "# --- 2. SQL SERVER CONFIGURATION ---\n",
    "# The connection string for your local SQL Server Express instance\n",
    "SQL_SERVER_NAME = r\"PRADEEP\\SQLEXPRESS\" # Use the raw string prefix 'r'\n",
    "SQL_DATABASE_NAME = \"SalesAnalytics\"\n",
    "SQL_TABLE_NAME = \"Live_Data_Staging\" # New table for the live data ingestion\n",
    "\n",
    "# You can use a specific driver. Common ones are 'ODBC Driver 17 for SQL Server' or 'SQL Server'.\n",
    "# Check your ODBC Data Sources (64-bit) for the exact name.\n",
    "SQL_DRIVER = \"ODBC Driver 17 for SQL Server\" \n",
    "\n",
    "# Use Windows Authentication (Trusted_Connection=yes) for local server.\n",
    "# If you use SQL Server Authentication, change to UID=<user>;PWD=<password>\n",
    "SQL_CONN_STRING = f\"DRIVER={{{SQL_DRIVER}}};SERVER={SQL_SERVER_NAME};DATABASE={SQL_DATABASE_NAME};Trusted_Connection=yes;\"\n",
    "\n",
    "def run_automation():\n",
    "    print(\"Starting data automation pipeline...\")\n",
    "\n",
    "    # --- 1. EXTRACT (Google Sheets) ---\n",
    "    try:\n",
    "        # Load credentials\n",
    "        credentials = Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=SCOPES)\n",
    "        gc = gspread.authorize(credentials)\n",
    "\n",
    "        # Open the spreadsheet\n",
    "        sh = gc.open(GOOGLE_SHEET_NAME)\n",
    "        # Assuming your data is in the first worksheet\n",
    "        worksheet = sh.worksheet(sh.sheet1.title)\n",
    "\n",
    "        # Get all records as a list of lists (including header)\n",
    "        data = worksheet.get_all_values()\n",
    "        \n",
    "        # Convert to a Pandas DataFrame\n",
    "        if not data:\n",
    "            print(\"Error: Google Sheet is empty.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        print(f\"Successfully extracted {len(df)} rows from Google Sheets.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google Sheets extraction: {e}\")\n",
    "        return\n",
    "\n",
    "   # --- 2. TRANSFORM (Data Cleaning/Preparation) ---\n",
    "    # Apply basic cleaning/type conversion here. \n",
    "\n",
    "    # Drop any rows where all values are missing (e.g., empty rows clients might add)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty after cleaning. Aborting load.\")\n",
    "        return\n",
    "        \n",
    "    # >>>>> START OF DATE CONVERSION BLOCK (FIXED INDENTATION) <<<<<\n",
    "    try:\n",
    "        # 1. Convert the column to datetime objects using the explicit format\n",
    "        #    NOTE: Ensure format='%d/%m/%Y' (DD/MM/YYYY) is correct for your Google Sheet.\n",
    "        df['OrderDate'] = pd.to_datetime(\n",
    "            df['OrderDate'], \n",
    "            format='%d/%m/%Y',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        \n",
    "        # 2. Convert valid datetime objects to the SQL-friendly string format (YYYY-MM-DD).\n",
    "        df['OrderDate'] = df['OrderDate'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 3. Replace the resulting 'NaT' string (from invalid dates) and empty strings with Python's None for SQL\n",
    "        df = df.replace({'NaT': None, '': None}) \n",
    "\n",
    "        print(\"OrderDate successfully standardized to YYYY-MM-DD format.\")\n",
    "\n",
    "    except KeyError:\n",
    "        # This executes if the 'OrderDate' column header is not found\n",
    "        print(\"Warning: 'OrderDate' column not found in Google Sheet data. Skipping date conversion.\")\n",
    "    except Exception as e:\n",
    "        # This handles any other unexpected error during date transformation\n",
    "        print(f\"Error during date standardization: {e}\")\n",
    "        return\n",
    "    # >>>>> END OF DATE CONVERSION BLOCK <<<<<\n",
    "    # >>>>> END OF DATE CONVERSION BLOCK <<<<<\n",
    "    \n",
    "    # --- 3. LOAD (To SQL Server) ---\n",
    "    CHUNK_SIZE = 10000  # Batch size for reliable insertion\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    try:\n",
    "        # Establish connection to SQL Server\n",
    "        conn = pyodbc.connect(SQL_CONN_STRING)\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Connected to SQL Server.\")\n",
    "\n",
    "        # 1. Clear the staging table to load fresh data (TRUNCATE is fast)\n",
    "        truncate_sql = f\"TRUNCATE TABLE {SQL_TABLE_NAME};\"\n",
    "        cursor.execute(truncate_sql)\n",
    "        conn.commit()\n",
    "        print(f\"Cleared existing data from {SQL_TABLE_NAME}.\")\n",
    "        \n",
    "        # 2. Build the dynamic INSERT statement\n",
    "        columns = ', '.join([f'[{col}]' for col in df.columns])\n",
    "        sql = f\"INSERT INTO {SQL_TABLE_NAME} ({columns}) VALUES ({', '.join(['?'] * len(df.columns))})\"\n",
    "        \n",
    "        rows_loaded = 0\n",
    "        \n",
    "        # 3. Iterate over the DataFrame in chunks and insert each batch\n",
    "        for i in range(0, total_rows, CHUNK_SIZE):\n",
    "            chunk_df = df.iloc[i:i + CHUNK_SIZE]\n",
    "            \n",
    "            # Prepare the list of tuples for insertion\n",
    "            data_to_insert = [tuple(row) for row in chunk_df.values]\n",
    "            \n",
    "            # Execute batch insert\n",
    "            cursor.executemany(sql, data_to_insert)\n",
    "            conn.commit()\n",
    "            \n",
    "            rows_loaded += len(chunk_df)\n",
    "            print(f\"Loaded {rows_loaded} of {total_rows} rows...\")\n",
    "            \n",
    "        print(f\"Successfully loaded ALL {total_rows} rows into {SQL_TABLE_NAME}.\")\n",
    "\n",
    "    except pyodbc.Error as ex:\n",
    "        sqlstate = ex.args[0]\n",
    "        print(f\"Error during SQL Load: {sqlstate}. Details: {ex}\")\n",
    "    finally:\n",
    "        if 'conn' in locals() and conn:\n",
    "            conn.close()\n",
    "            print(\"SQL Server connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_automation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e851b2-b194-4698-a4c2-929547f5847e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
